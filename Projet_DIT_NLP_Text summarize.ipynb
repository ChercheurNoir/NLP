{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"],"metadata":{"id":"mZTO9a3gTCJO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install sumy"],"metadata":{"id":"VM7V2XxDjrZ_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from bs4 import BeautifulSoup\n","from requests import get\n","from sumy.parsers.plaintext import PlaintextParser\n","from sumy.nlp.tokenizers import Tokenizer\n","from sumy.summarizers.text_rank import TextRankSummarizer\n","from sumy.summarizers.lex_rank import LexRankSummarizer\n","from sumy.summarizers.lsa import LsaSummarizer\n","import nltk\n","\n","# Télécharger les ressources NLTK nécessaires\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","\n","def extract_text_from_wikipedia(url):\n","    resp = get(url)\n","    article_soup = BeautifulSoup(resp.text, 'html.parser')\n","    paragraphs = article_soup.find_all('p')\n","    article_text = \" \".join(p.text for p in paragraphs)\n","    return article_text\n","\n","def textrank_summarize(text, num_sentences=5):\n","    parser = PlaintextParser.from_string(text, Tokenizer(\"english\"))\n","    summarizer = TextRankSummarizer()\n","    summary = summarizer(parser.document, num_sentences)\n","    return \" \".join(str(sentence) for sentence in summary)\n","\n","def lexrank_summarize(text, num_sentences=5):\n","    parser = PlaintextParser.from_string(text, Tokenizer(\"english\"))\n","    summarizer = LexRankSummarizer()\n","    summary = summarizer(parser.document, num_sentences)\n","    return \" \".join(str(sentence) for sentence in summary)\n","\n","def lsa_summarize(text, num_sentences=5):\n","    parser = PlaintextParser.from_string(text, Tokenizer(\"english\"))\n","    summarizer = LsaSummarizer()\n","    summary = summarizer(parser.document, num_sentences)\n","    return \" \".join(str(sentence) for sentence in summary)\n","\n","# Extraire le texte de la cuisine iranienne en anglais\n","english_url = 'https://en.wikipedia.org/wiki/Iranian_cuisine'\n","english_text = extract_text_from_wikipedia(english_url)\n","\n","# Extraire le texte de la cuisine iranienne en français\n","french_url = 'https://fr.wikipedia.org/wiki/Cuisine_iranienne'\n","french_text = extract_text_from_wikipedia(french_url)\n","\n","# Résumé du texte en anglais avec TextRank\n","english_summary_textrank = textrank_summarize(english_text)\n","print(\"English Summary (TextRank):\", english_summary_textrank)\n","\n","# Résumé du texte en anglais avec LexRank\n","english_summary_lexrank = lexrank_summarize(english_text)\n","print(\"English Summary (LexRank):\", english_summary_lexrank)\n","\n","# Résumé du texte en anglais avec LSA\n","english_summary_lsa = lsa_summarize(english_text)\n","print(\"English Summary (LSA):\", english_summary_lsa)\n","\n","# Résumé du texte en français avec TextRank\n","french_summary_textrank = textrank_summarize(french_text)\n","print(\"French Summary (TextRank):\", french_summary_textrank)\n","\n","# Résumé du texte en français avec LexRank\n","french_summary_lexrank = lexrank_summarize(french_text)\n","print(\"French Summary (LexRank):\", french_summary_lexrank)\n","\n","# Résumé du texte en français avec LSA\n","french_summary_lsa = lsa_summarize(french_text)\n","print(\"French Summary (LSA):\", french_summary_lsa)\n"],"metadata":{"id":"knc8xnrETShH"},"execution_count":null,"outputs":[]}]}